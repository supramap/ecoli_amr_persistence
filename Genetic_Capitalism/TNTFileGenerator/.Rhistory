amr.binset <- ((amr.strsets == amr.strset)*1)
((amr.strsets == amr.strset)*1)
((amr.strsets == amr.strset[[1]])*1)
amr.binset <- paste((amr.strsets == amr.strset[[1]])*1, collapse = "")
paste((amr.strsets == amr.strset[[1]])*1, collapse = "")
amr.binset <- amr.strset %>% lapply(paste((amr.strsets == .)*1, collapse = ""))
amr.binset <- amr.strset %>% paste((amr.strsets == .)*1, collapse = "")
amr.strset %>% paste((amr.strsets == .)*1, collapse = "")
amr.binset <- lapply(amr.strset, function(x){paste((amr.strsets == x)*1, collapse = "")})
amr.binset
amr.strset[[1]]
amr.strset[1]
amr.binset[[1]]
amr.binset[1]
for
''
writeLines(names(amr.binset[1]), tree.file)
tree.file <- file("e.coli.tnt")
writeLines(names(amr.binset[1]), tree.file)
close(tree.file)
writeLines(names(amr.binset[[1]]), tree.file)
writeLines(amr.binset[[1]], tree.file)
tree.file <- file("e.coli.tnt")
writeLines(names(amr.binset[1]), tree.file)
writeLines(amr.binset[[1]], tree.file)
close(tree.file)
tree.file <- file("e.coli.tnt")
writeLines(names(amr.binset[1]), tree.file)
?writeLines
writeLine(names(amr.binset[1]), tree.file)
cat("", file="e.coli.tnt")
source('/Volumes/GoogleDrive/My Drive/research/AMR/src/Trees/tree.R', echo=TRUE)
cat(names(amr.binset[1]), file="e.coli.tnt", sep="\n", append=T)
cat(amr.binset[[1]], file="e.coli.tnt", sep="\n", append=T)
cat("", file="e.coli.tnt")
for (i in 1:length(amr.binset)) {
cat(names(amr.binset[i]), file="e.coli.tnt", sep="\n", append=T)
cat(amr.binset[[i]], file="e.coli.tnt", sep="\n", append=T)
}
setwd("/Volumes/GoogleDrive/My Drive/research/AMR/bsve2016/bsve2016/AMR_Analysis/GenotypeOnly/TNTFileGenerator")
#sed 's/'\)'*'\('*'\ '*PDT/,PDT/g' e.coli.paren | sed 's/^,//g' | sed 's/'\)'*;$//g' > e.coli.ids
#---------
##obsolete
#---------
#sed 's/$/~/
#:a
#s/\(PDT[0-9]*\.[0-9]\)\(.*~.*\)/\2,\1/
#ta
#s/^.*~//' PDG000000004.1024.reference_target.tree.newick > e.coli.ids
#---------
pdt <- unique(names(read.csv("e.coli.ids")))
#sed 's/'\)'*'\('*'\ '*PDT/,PDT/g' e.coli.paren | sed 's/^,//g' | sed 's/'\)'*;$//g' > e.coli.ids
#---------
##obsolete
#---------
#sed 's/$/~/
#:a
#s/\(PDT[0-9]*\.[0-9]\)\(.*~.*\)/\2,\1/
#ta
#s/^.*~//' PDG000000004.1024.reference_target.tree.newick > e.coli.ids
#---------
pdt <- unique(names(read.csv("e.coli.ids")))
#sed 's/'\)'*'\('*'\ '*PDT/,PDT/g' e.coli.paren | sed 's/^,//g' | sed 's/'\)'*;$//g' > e.coli.ids
#---------
##obsolete
#---------
#sed 's/$/~/
#:a
#s/\(PDT[0-9]*\.[0-9]\)\(.*~.*\)/\2,\1/
#ta
#s/^.*~//' PDG000000004.1024.reference_target.tree.newick > e.coli.ids
#---------
pdt <- unique(names(read.csv("e.coli.ids")))
#sed 's/'\)'*'\('*'\ '*PDT/,PDT/g' e.coli.paren | sed 's/^,//g' | sed 's/'\)'*;$//g' > e.coli.ids
#---------
##obsolete
#---------
#sed 's/$/~/
#:a
#s/\(PDT[0-9]*\.[0-9]\)\(.*~.*\)/\2,\1/
#ta
#s/^.*~//' PDG000000004.1024.reference_target.tree.newick > e.coli.ids
#---------
pdt <- unique(names(read.csv("e.coli.ids")))
library(jsonlite)
library(stringr)
setwd("/Volumes/GoogleDrive/My Drive/research/AMR/bsve2016/AMR_Analysis/GenotypeOnly/TNTFileGenerator")
#sed 's/'\)'*'\('*'\ '*PDT/,PDT/g' e.coli.paren | sed 's/^,//g' | sed 's/'\)'*;$//g' > e.coli.ids
#---------
##obsolete
#---------
#sed 's/$/~/
#:a
#s/\(PDT[0-9]*\.[0-9]\)\(.*~.*\)/\2,\1/
#ta
#s/^.*~//' PDG000000004.1024.reference_target.tree.newick > e.coli.ids
#---------
pdt <- unique(names(read.csv("e.coli.ids")))
#json.stream <- fromJSON("https://www.ncbi.nlm.nih.gov/pathogens/ngram?start=0&limit=1000000&q=%5Bdisplay()%2Chist(geo_loc_name%2Cisolation_source%2Ccollected_by%2Chost%2Cproperty%2Ctarget_creation_date)%5D.from(pathogen).usingschema(%2Fschema%2Fpathogen).matching(status%3D%3D%5B%22current%22%5D+and+q%3D%3D%22taxgroup_name%253A%2522E.coli%2520and%2520Shigella%2522%22).sort(target_creation_date%2Cdesc)&_search=false&rows=20&page=1&sidx=target_creation_date&sord=desc)")
#saveRDS(json.stream, file = "e.coli.RDS")
json.stream <- readRDS("e.coli.RDS")
id <- substr(json.stream[["ngout"]][["data"]][["content"]][["id"]], 19, 33)
genotypes <- json.stream[["ngout"]][["data"]][["content"]][["AMR_genotypes"]]
names(genotypes) <- id
genotypes[!(names(genotypes) %in% pdt)] <- NULL
# ---------
# Genotypes
# ---------
genotypesall <- unique(unlist(genotypes))
genobins <- lapply(genotypes, function(x){paste((genotypesall %in% x) * 1, collapse = "")})
cat("mxram 800000", "xread", paste(c(length(genobins), length(genobinset)), collapse = " "), file = "e.coli.genotypes.tnt.head", sep = "\n")
cat("mxram 800000", "xread", paste(c(length(genobins), length(genotypes)), collapse = " "), file = "e.coli.genotypes.tnt.head", sep = "\n")
cat(as.vector(paste(names(genobins), unlist(genobins), sep = " ")), file = "e.coli.genotypes.tnt.head", sep = "\n", append = T)
cat(";", "tread", file = "e.coli.genotypes.tnt.head", sep = "\n", append = T)
cat(";", "", "cnames", file = "e.coli.genotypes.tnt.tail", sep = "\n")
for (i in 1:length(genotypesall)) {
cat(paste0("{", (i - 1), " 'genotype_", genotypesall[i], "' absent present;"), file = "e.coli.genotypes.tnt.tail", sep = "\n", append = T)
}
cat(";", "proc /;", file = "e.coli.genotypes.tnt.tail", sep = "\n", append = T)
system("cat e.coli.genotypes.tnt.head e.coli.paren e.coli.genotypes.tnt.tail > e.coli.genotypes.tnt")
id <- substr(json.stream[["ngout"]][["data"]][["content"]][["id"]], 19, 33)
creation_date <- json.stream[["ngout"]][["data"]][["content"]][["target_creation_date"]]
location <- json.stream[["ngout"]][["data"]][["content"]][["geo_loc_name"]]
isolation_type <- json.stream[["ngout"]][["data"]][["content"]][["epi_type"]]
genotypes <- json.stream[["ngout"]][["data"]][["content"]][["AMR_genotypes"]]
df <- data.frame(id, creation_date, location, isolation_type, genotypes)
names(genotypes) <- id
genotypes[!(names(genotypes) %in% pdt)] <- NULL
df <- data.frame(id, creation_date, location, isolation_type)
df <- df[!(df$id %in% pdt)] <- NULL
df <- df[!(df$id %in% pdt),] <- NULL
df[!(df$id %in% pdt),]
id <- substr(json.stream[["ngout"]][["data"]][["content"]][["id"]], 19, 33)
creation_date <- as.date(json.stream[["ngout"]][["data"]][["content"]][["target_creation_date"]])
creation_date <- as.Date(json.stream[["ngout"]][["data"]][["content"]][["target_creation_date"]])
creation_date
json.stream <- fromJSON("https://www.ncbi.nlm.nih.gov/pathogens/ngram?start=0&limit=1000000&q=%5Bdisplay()%2Chist(geo_loc_name%2Cisolation_source%2Ccollected_by%2Chost%2Cproperty%2Ctarget_creation_date)%5D.from(pathogen).usingschema(%2Fschema%2Fpathogen).matching(status%3D%3D%5B%22current%22%5D+and+q%3D%3D%22taxgroup_name%253A%2522E.coli%2520and%2520Shigella%2522%22).sort(target_creation_date%2Casc)&_search=false&rows=20&page=1&sidx=target_creation_date&sord=asc)")
json.stream[["ngout"]][["data"]][["content"]][["target_creation_date"]]
id <- substr(json.stream[["ngout"]][["data"]][["content"]][["id"]], 19, 33)
creation_date_time <- as.POSIXct(json.stream[["ngout"]][["data"]][["content"]][["target_creation_date"]], format = "%Y-%m-%dT%H:%M:%SZ")
creation_date_time[1]
location <- json.stream[["ngout"]][["data"]][["content"]][["geo_loc_name"]]
isolation_type <- json.stream[["ngout"]][["data"]][["content"]][["epi_type"]]
genotypes <- json.stream[["ngout"]][["data"]][["content"]][["AMR_genotypes"]]
df <- data.frame(id, creation_date, location, isolation_type)
df <- data.frame(id, creation_date_time, location, isolation_type)
rm(creation_date)
names(genotypes) <- id
genotypes[!(names(genotypes) %in% pdt)] <- NULL
df <- df[!(df$id %in% pdt),] <- NULL
df <- df[df$id %in% pdt,]
df <- data.frame(id, creation_date_time, location, isolation_type)
df[!(df$id %in% pdt),] <- NULL
df <- df[df$id %in% pdt,]
# ---------
# Genotypes
# ---------
genotypesall <- unique(unlist(genotypes))
genobins <- lapply(genotypes, function(x){paste((genotypesall %in% x) * 1, collapse = "")})
cat("mxram 800000", "xread", paste(c(length(genotypesall), length(genobins)), collapse = " "), file = "e.coli.genotypes.tnt.head", sep = "\n")
cat(as.vector(paste(names(genobins), unlist(genobins), sep = " ")), file = "e.coli.genotypes.tnt.head", sep = "\n", append = T)
cat(";", "tread", file = "e.coli.genotypes.tnt.head", sep = "\n", append = T)
cat(";", "", "cnames", file = "e.coli.genotypes.tnt.tail", sep = "\n")
for (i in 1:length(genotypesall)) {
cat(paste0("{", (i - 1), " 'genotype_", genotypesall[i], "' absent present;"), file = "e.coli.genotypes.tnt.tail", sep = "\n", append = T)
}
cat(";", "proc /;", file = "e.coli.genotypes.tnt.tail", sep = "\n", append = T)
system("cat e.coli.genotypes.tnt.head e.coli.paren e.coli.genotypes.tnt.tail > e.coli.genotypes.tnt")
# -------------
# Genotype Sets
# -------------
genotypeset <- lapply(genotypes, paste, collapse="_")
genotypesets <- unique(unlist(genotypeset))
genobinset <- lapply(genotypeset, function(x){paste((genotypesets == x) * 1, collapse = "")})
cat("mxram 800000", "xread", paste(c(length(genotypesets), length(genobinset)), collapse = " "), file = "e.coli.tnt.head", sep = "\n")
cat(as.vector(paste(names(genobinset), unlist(genobinset), sep = " ")), file = "e.coli.tnt.head", sep = "\n", append = T)
cat(";", "tread", file = "e.coli.tnt.head", sep = "\n", append = T)
cat(";", "", "cnames", file = "e.coli.tnt.tail", sep = "\n")
for (i in 1:length(genotypesets)) {
cat(paste0("{", (i - 1), " 'genotype_set_", genotypesets[i], "' absent present;"), file = "e.coli.tnt.tail", sep = "\n", append = T)
}
cat(";", "proc /;", file = "e.coli.tnt.tail", sep = "\n", append = T)
system("cat e.coli.tnt.head e.coli.paren e.coli.tnt.tail > e.coli.tnt")
setwd("/Volumes/GoogleDrive/My Drive/research/AMR/bsve2016/AMR_Analysis/GenotypeOnly/TNTFileGenerator")
system("cat e.coli.tnt.head e.coli.paren e.coli.tnt.tail > e.coli.tnt")
cat("mxram 800000", "xread", paste(c(length(genotypesall), length(genobins)), collapse = " "), file = "e.coli.genotypes.tnt.head", sep = "\n")
cat(as.vector(paste(names(genobins), unlist(genobins), sep = " ")), file = "e.coli.genotypes.tnt.head", sep = "\n", append = T)
cat(";", "tread", file = "e.coli.genotypes.tnt.head", sep = "\n", append = T)
cat(";", "", "cnames", file = "e.coli.genotypes.tnt.tail", sep = "\n")
for (i in 1:length(genotypesall)) {
cat(paste0("{", (i - 1), " 'genotype_", genotypesall[i], "' absent present;"), file = "e.coli.genotypes.tnt.tail", sep = "\n", append = T)
}
cat(";", "proc /;", file = "e.coli.genotypes.tnt.tail", sep = "\n", append = T)
system("cat e.coli.genotypes.tnt.head e.coli.paren e.coli.genotypes.tnt.tail > e.coli.genotypes.tnt")
cat("mxram 800000", "xread", paste(c(length(genotypesets), length(genobinset)), collapse = " "), file = "e.coli.tnt.head", sep = "\n")
cat(as.vector(paste(names(genobinset), unlist(genobinset), sep = " ")), file = "e.coli.tnt.head", sep = "\n", append = T)
cat(";", "tread", file = "e.coli.tnt.head", sep = "\n", append = T)
cat(";", "", "cnames", file = "e.coli.tnt.tail", sep = "\n")
for (i in 1:length(genotypesets)) {
cat(paste0("{", (i - 1), " 'genotype_set_", genotypesets[i], "' absent present;"), file = "e.coli.tnt.tail", sep = "\n", append = T)
}
cat(";", "proc /;", file = "e.coli.tnt.tail", sep = "\n", append = T)
system("cat e.coli.tnt.head e.coli.paren e.coli.tnt.tail > e.coli.tnt")
genobins
unlist(genobins)
write.csv(data.frame(df, unlist(genobins)))
write.csv(data.frame(df, unlist(genobins)))
write.csv(data.frame(df, unlist(genobins)), "e.coli.genotypes.meta.csv")
write.csv(data.frame(df, unlist(genobinset)), "e.coli.meta.csv")
library(ISLR)
#Logistic regression model
lg.model <- glm(default ~ balance, family = binomial, data = Default)
summary(lg.model)
coef(lg.model)
coef(lg.model)[1]
exp(coef(lg.model)[1])
exp(unlist(coef(lg.model)[1]))
exp(unlist(coef(lg.model))[1])
exp(as.vector(coef(lg.model))[1])
#Logistic regression model looks like...
#P(default | balance = $1,300) = exp(beta_0 + beta_1 * balance) / (1 + exp(beta_0 + beta_1 * balance))
logreg <- function(x){return(
exp(as.vector(coef(lg.model))[1] + as.vector(coef(lg.model))[2] * x))
/
(1 + exp(as.vector(coef(lg.model))[1] + as.vector(coef(lg.model))[2] * x))
}
#Logistic regression model looks like...
#P(default | balance = $1,300) = exp(beta_0 + beta_1 * balance) / (1 + exp(beta_0 + beta_1 * balance))
logreg <- function(x){
return(
exp(as.vector(coef(lg.model))[1] + as.vector(coef(lg.model))[2] * x)
/
(1 + exp(as.vector(coef(lg.model))[1] + as.vector(coef(lg.model))[2] * x))
)
}
logreg(1300)
logreg(2500)
lg.prob = predict(lg.model, type = "response")
View(Default)
lg.prob = predict(lg.model, type = "response")
lg.pred = rep("No", nrow(Default))
lg.pred[lg.prob > 0.5] <- "Yes"
table(lg.pred, Default$default)
lg.pred[lg.prob > 0.4] <- "Yes"
table(lg.pred, Default$default)
lg.pred[lg.prob > 0.3] <- "Yes"
table(lg.pred, Default$default)
mean(lg.pred != Default$default)
lg.pred[lg.prob > 0.2] <- "Yes"
mean(lg.pred != Default$default) # error rate
lg.pred[lg.prob > 0.25] <- "Yes"
mean(lg.pred != Default$default) # error rate
lg.pred[lg.prob > 0.275] <- "Yes"
mean(lg.pred != Default$default) # error rate
lg.prob <- predict(lg.model, type = "response") # re-predict using the Default dataset and the logistic regression model
lg.pred <- rep("No", nrow(Default))
lg.pred[lg.prob > 0.275] <- "Yes"
mean(lg.pred != Default$default) # error rate
lg.prob <- predict(lg.model, type = "response") # re-predict using the Default dataset and the logistic regression model
lg.pred <- rep("No", nrow(Default))
lg.pred[lg.prob > 0.3] <- "Yes"
#table(lg.pred, Default$default)  # table of true/false positive/negative
mean(lg.pred != Default$default) # error rate
lg.prob <- predict(lg.model, type = "response") # re-predict using the Default dataset and the logistic regression model
lg.pred <- rep("No", nrow(Default))
lg.pred[lg.prob > 0.25] <- "Yes"
#table(lg.pred, Default$default)  # table of true/false positive/negative
mean(lg.pred != Default$default) # error rate
lg.prob <- predict(lg.model, type = "response") # re-predict using the Default dataset and the logistic regression model
lg.pred <- rep("No", nrow(Default))
lg.pred[lg.prob > 0.3] <- "Yes"
#table(lg.pred, Default$default)  # table of true/false positive/negative
mean(lg.pred != Default$default) # error rate
i = 3
test <- subset(Default[shuffle,], folds==i, drop=TRUE)
#10-fold cross-validation
shuffle <- sample(nrow(Default))
nfold = 10
lg.error <- rep(0, nfold)
folds = cut(1:nrow(Default), breaks=nfold, labels=FALSE)
test <- subset(Default[shuffle,], folds==i, drop=TRUE)
train <- subset(Default[shuffle,], folds!=i, drop=TRUE)
# test.x <- subset(Default$balance[shuffle], folds==i, drop=TRUE)
# test.y <- subset(Default$default[shuffle], folds==i, drop=TRUE)
# train.x <- subset(Default$balance[shuffle], folds!=i, drop=TRUE)
# train.y <- subset(Default$default[shuffle], folds!=i, drop=TRUE)
# train <- data.frame(balance=train.x, default=train.y)
# test <- data.frame(balance=test.x, default=test.y)
lg.model <- glm(default ~ balance, family = binomial, data = train) # build the model using the training set
lg.prob <- predict(test$balance, type = "response") # re-predict using the Default dataset and the logistic regression model
?predict
lg.prob <- predict(lg.model, test$balance, type = "response") # re-predict using the Default dataset and the logistic regression model
lg.prob <- predict(lg.model, test, type = "response") # re-predict using the Default dataset and the logistic regression model
lg.pred <- rep("No", nrow(Default))
lg.pred[lg.prob > 0.3] <- "Yes"
lg.error[i] <- mean(lg.model != subset(Default$default[shuffle], folds==i, drop=TRUE))
lg.error[i] <- mean(lg.pred != test$default)
lg.error[i]
for (i in 1:nfold) {
test <- subset(Default[shuffle,], folds==i, drop=TRUE)
train <- subset(Default[shuffle,], folds!=i, drop=TRUE)
# test.x <- subset(Default$balance[shuffle], folds==i, drop=TRUE)
# test.y <- subset(Default$default[shuffle], folds==i, drop=TRUE)
# train.x <- subset(Default$balance[shuffle], folds!=i, drop=TRUE)
# train.y <- subset(Default$default[shuffle], folds!=i, drop=TRUE)
# train <- data.frame(balance=train.x, default=train.y)
# test <- data.frame(balance=test.x, default=test.y)
lg.model <- glm(default ~ balance, family = binomial, data = train) # build the model using the training set
lg.prob <- predict(lg.model, test, type = "response") # re-predict using the Default dataset and the logistic regression model
lg.pred <- rep("No", nrow(Default))
lg.pred[lg.prob > 0.3] <- "Yes"
lg.error[i] <- mean(lg.pred != test$default)
}
print(mean(lg.error))
shuffle
Default[shuffle,]
lg.pred != test$default
mean(lg.pred != test$default)
i
shuffle <- sample(nrow(Default))
nfold = 10
lg.error <- rep(0, nfold)
folds = cut(1:nrow(Default), breaks=nfold, labels=FALSE)
for (i in 1:nfold) {
test <- subset(Default[shuffle,], fold==i, drop=TRUE)
train <- subset(Default[shuffle,], fold!=i, drop=TRUE)
lg.model <- glm(default ~ balance, family = binomial, data = train) # build the model using the training set\
# predict the test dataset using the logistic regression model built from training dataset
lg.prob <- predict(lg.model, test, type = "response")
lg.pred <- rep("No", nrow(Default))
lg.pred[lg.prob > 0.3] <- "Yes"
lg.error[i] <- mean(lg.pred != test$default)
}
print(mean(lg.error))
shuffle <- sample(nrow(Default))
nfold = 10
lg.error <- rep(0, nfold)
folds = cut(1:nrow(Default), breaks=nfold, labels=FALSE)
for (i in 1:nfold) {
test <- subset(Default[shuffle,], folds==i, drop=TRUE)
train <- subset(Default[shuffle,], folds!=i, drop=TRUE)
lg.model <- glm(default ~ balance, family = binomial, data = train) # build the model using the training set\
# predict the test dataset using the logistic regression model built from training dataset
lg.prob <- predict(lg.model, test, type = "response")
lg.pred <- rep("No", nrow(Default))
lg.pred[lg.prob > 0.3] <- "Yes"
lg.error[i] <- mean(lg.pred != test$default)
}
print(mean(lg.error))
#Classification
plot(Default$balance, Default$income, col=ifelse(Default$default == "No", "lightblue", "orange"), pch=ifelse(Default$default == "No", "o", "+"), xlab="Balance", ylab="Income")
plot(Default$default, Default$balance, col=c("lightblue", "orange"), xlab="Default", ylab="Balance")
abline(1300, 0)
plot(Default$default, Default$income, col=c("lightblue", "orange"), xlab="Default", ylab="Income")
#Classification
plot(Default$balance, Default$income, col=ifelse(Default$default == "No", "lightblue", "orange"), pch=ifelse(Default$default == "No", "o", "+"), xlab="Balance", ylab="Income")
plot(Default$default, Default$balance, col=c("lightblue", "orange"), xlab="Default", ylab="Balance")
abline(1300, 0)
DefaultNo <- Default[balance < 1300,]
DefaultNo <- Default[Default$balance < 1300,]
DefaultYes <- Default[Default$balance >= 1300,]
nrow(Default)
nrow(DefaultNo)
nrow(DefaultYes)
nrow(DefaultNo)+nrow(DefaultYes)
plot(DefaultNo$default, DefaultNo$income, col=c("lightblue", "orange"), xlab="Default", ylab="Income")
plot(DefaultYes$default, DefaultYes$income, col=c("lightblue", "orange"), xlab="Default", ylab="Income")
plot(DefaultNo$default, DefaultNo$student, col=c("lightblue", "orange"), xlab="Default", ylab="Income")
plot(DefaultYes$default, DefaultYes$student, col=c("lightblue", "orange"), xlab="Default", ylab="Student")
attach(Carseats)
Carseats$Sales
Sales
View(Carseats)
Carseats$Sales
Sales
Carseats$Population
Population
HighSales <- ifelse(Sales <= 8, "No", "Yes")
CarseatsHighSales <- data.frame(Carseats, HighSales)
View(CarseatsHighSales)
detach(Carseats)
attach(CarseatsHighSales)
plot(HighSales, ShelveLoc, col=c("lightblue", "orange"), xlab="High Sales", ylab="Shelve Location")
plot(HighSales, Price, col=c("lightblue", "orange"), xlab="High Sales", ylab="Price")
min(Price)
max(Price)
plot(CarseatsHighSales$HighSales, CarseatsHighSales$Price, col=c("lightblue", "orange"), xlab="High Sales", ylab="Price")
plot(CarseatsHighSales$HighSales, CarseatsHighSales$ShelveLoc, col=c("lightblue", "orange"), xlab="High Sales", ylab="Shelve Location")
plot(CarseatsHighSales$HighSales, CarseatsHighSales$Income, col=c("lightblue", "orange"), xlab="High Sales", ylab="Income")
plot(CarseatsHighSales$HighSales, CarseatsHighSales$CompPrice, col=c("lightblue", "orange"), xlab="High Sales", ylab="Comp Price")
plot(CarseatsHighSales$HighSales, CarseatsHighSales$ShelveLoc, col=c("lightblue", "orange"), xlab="High Sales", ylab="Shelve Location")
plot(CarseatsHighSales$HighSales, CarseatsHighSales$Price, col=c("lightblue", "orange"), xlab="High Sales", ylab="Price")
CSHSBY <- CarseatsHighSales[CarseatsHighSales$ShelveLoc == "Bad",]
CSHSBN <- CarseatsHighSales[CarseatsHighSales$ShelveLoc != "Bad",]
plot(CSHSBN$HighSales, CSHSBN$Price, col=c("lightblue", "orange"), xlab="High Sales", ylab="Price")
plot(CSHSBY$HighSales, CSHSBY$Price, col=c("lightblue", "orange"), xlab="High Sales", ylab="Price")
CSHSBYP100A <- CSHSBY[CSHSBY$Price >= 100,]
plot(CSHSBY100A$HighSales, CSHSBY100A$Income, col=c("lightblue", "orange"), xlab="High Sales", ylab="Price")
CSHSBYP100A <- CSHSBY[CSHSBY$Price >= 100,]
plot(CSHSBY100A$HighSales, CSHSBY100A$Income, col=c("lightblue", "orange"), xlab="High Sales", ylab="Income")
CSHSBYP100A <- CSHSBY[CSHSBY$Price >= 100,]
plot(CSHSBYP100A$HighSales, CSHSBYP100A$Income, col=c("lightblue", "orange"), xlab="High Sales", ylab="Income")
CSHSBNP100A <- CSHSBY[CSHSBN$Price < 100,]
CSHSBNP100A <- CSHSBY[CSHSBN$Price < 100,]
plot(CSHSBNP100A$HighSales, CSHSBNP100A$Income, col=c("lightblue", "orange"), xlab="High Sales", ylab="Income")
pairs(CarseatsHighSales)
pairs(CarseatsHighSales)
nrow(Carseats)
nrow(CSHSBN)
nrow(CSHSBY)
nrow(CSHSBYP100A)
nrow(CSHSBNP100A)
setwd("/Volumes/GoogleDrive/My Drive/classes/SEGR3105-F18")
hrdz <- read.csv("heart-disease.csv")
model.tree <- tree(diseased ~ ., data = hrdz)
library(tree)
install.packages("tree")
library(tree)
model.tree <- tree(diseased ~ ., data = hrdz)
model.tree
table(predict(model.tree, type="class"), hrdz$diseased)
model.glm <- glm(diseased ~ ., data = hrdz)
model.glm <- glm(diseased ~ ., data = hrdz, family = binomial)
model.svm <- svm(diseased ~ ., data = hrdz)
library(e1071)
install.packages(e1071)
install.packages("e1071")
model.svm <- svm(diseased ~ ., data = hrdz)
library(e1071)
model.svm <- svm(diseased ~ ., data = hrdz)
table(predict(model.svm, type="class"), hrdz$diseased)
library(class)
model.knn <- knn(data[,-14], data[,-14], data[,14], k=5)
View(data)
model.knn <- knn(hrdz[,-14], hrdz[,-14], hrdz[,14], k=5)
View(hrdz)
?read.csv
hrdz <- read.csv("heart-disease.csv", na.strings = "?")
model.knn <- knn(hrdz[,-14], hrdz[,-14], hrdz[,14], k=5)
hrdz0 <- na.omit(hrdz)
nrow(hrdz0)
nrow(hrdz)
na.action(hrdz)
nrow(hrdz)
median(hrdz$vessels)
hrdz <- read.csv("heart-disease.csv", na.strings = "?")
model.knn <- knn(hrdz[,-14], hrdz[,-14], hrdz[,14], k=5)
hrdz <- read.csv("heart-disease.csv")
model.knn <- knn(hrdz[,-14], hrdz[,-14], hrdz[,14], k=5)
hrdz <- read.csv("heart-disease.csv")
model.knn <- knn(hrdz[,-14], hrdz[,-14], hrdz[,14], k=5)
View(hrdz)
hrdz0 <- na.omit(hrdz)
nrow(hrdz0)
model.knn <- knn(hrdz0[,-14], hrdz0[,-14], hrdz0[,14], k=5)
hrdz$chest.pain
as.factor(hrdz$chest.pain)
as.integer(as.factor(hrdz$chest.pain))
library(knncat)
install.packages("knncat")
library(knncat)
model.knn <- knncat(hrdz[,-14], hrdz[,-14], hrdz[,14], k=5)
model.knn <- knn(hrdz[,-c(2,3,6,7,9,11,13,14)], hrdz[,-c(2,3,6,7,9,11,13,14)], hrdz[,14], k=5)
table(model.knn, hrdz$diseased)
model.knn <- knn(hrdz[,c(2,3,6,7,9,11,13)], hrdz[,c(2,3,6,7,9,11,13)], hrdz[,14], k=5)
setwd("/Volumes/GoogleDrive/My Drive/research/AMR/bsve2016/AMR_Analysis/GenotypeOnly/TNTFileGenerator")
library(jsonlite)
library(stringr)
# Run these *nix commands
#sed 's/'\''//g' PDG000000004.1024.reference_target.tree.newick | sed 's/:-*[0-9]\.*[0-9]*\(e-[0-9]*\)*//g' | sed 's/,'\('/'\('/g' | sed 's/,/ /g' > e.coli.paren
#sed 's/'\)'*'\('*'\ '*PDT/,PDT/g' e.coli.paren | sed 's/^,//g' | sed 's/'\)'*;$//g' > e.coli.ids
#---------
pdt <- unique(names(read.csv("e.coli.ids")))
#json.stream <- fromJSON("https://www.ncbi.nlm.nih.gov/pathogens/ngram?start=0&limit=1000000&q=%5Bdisplay()%2Chist(geo_loc_name%2Cisolation_source%2Ccollected_by%2Chost%2Cproperty%2Ctarget_creation_date)%5D.from(pathogen).usingschema(%2Fschema%2Fpathogen).matching(status%3D%3D%5B%22current%22%5D+and+q%3D%3D%22taxgroup_name%253A%2522E.coli%2520and%2520Shigella%2522%22).sort(target_creation_date%2Casc)&_search=false&rows=20&page=1&sidx=target_creation_date&sord=asc)")
#saveRDS(json.stream, file = "e.coli.RDS")
json.stream <- readRDS("e.coli.RDS")
id <- substr(json.stream[["ngout"]][["data"]][["content"]][["id"]], 19, 33)
creation_date_time <- as.POSIXct(json.stream[["ngout"]][["data"]][["content"]][["target_creation_date"]], format = "%Y-%m-%dT%H:%M:%SZ")
collection_year <- as.numeric(substr(json.stream[["ngout"]][["data"]][["content"]][["collection_date"]], 1, 4))
collection_year[is.na(collection_year)] <- as.numeric(format(creation_date_time[is.na(collection_year)], "%Y"))
location <- json.stream[["ngout"]][["data"]][["content"]][["geo_loc_name"]]
isolation_type <- json.stream[["ngout"]][["data"]][["content"]][["epi_type"]]
isolation_source <- json.stream[["ngout"]][["data"]][["content"]][["isolation_source"]]
genotypes <- json.stream[["ngout"]][["data"]][["content"]][["AMR_genotypes"]]
df <- data.frame(id, creation_date_time, collection_year, location, isolation_type, isolation_source)
df <- df[df$id %in% pdt,]
names(genotypes) <- id
genotypes[!(names(genotypes) %in% pdt)] <- NULL
pdtfilter <- c("PDT000357631.1", "PDT000080885.1", "PDT000080595.1", "PDT000080890.1", "PDT000078648.1", "PDT000080785.1")
dffilter <- df[df$id %in% pdtfilter,]
View(dffilter)
View(genotypes)
merge(genotypes)
?merge
unlist(genotypes)
lapply(genotypes, paste, sep=",")
genotypes[["PDT000387738.1"]]
paste(genotypes[["PDT000387738.1"]], sep=",")
paste(genotypes[["PDT000387738.1"]], collapse=",")
lapply(genotypes, paste, collapse=", ")
df2 <- data.frame(df, lapply(genotypes, paste, collapse=", "))
dffilter <- df[df2$id %in% pdtfilter,]
View(dffilter)
df2 <- data.frame(df, unlist(lapply(genotypes, paste, collapse=", ")))
dffilter <- df[df2$id %in% pdtfilter,]
View(dffilter)
View(df2)
dffilter <- df2[df2$id %in% pdtfilter,]
View(dffilter)
View(dffilter)
View(df2)
pdtfilter
