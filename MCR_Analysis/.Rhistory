genotypes <- sort(unique(unlist(mcr.subset)))
## Convert to transactions for the a priori algorithm
mcr.transactions <- as(mcr.subset, 'transactions')
## Define rule sizes and isolate counts to explore
rulesizes <- seq(2, 14, by = 1)
isolatesizes <- lapply(amr.list.raw, length) %>%
matrix() %>%
data.frame()
colnames(isolatesizes) <- c("size")
isolatesizes$size <- as.factor(as.character(isolatesizes$size))
isolatesizes <- isolatesizes %>%
group_by(size) %>%
tally()
isolatesizes$size <- as.numeric(isolatesizes$size)
isolatesizes <- isolatesizes %>%
arrange() %>%
filter(size <= max(rulesizes) & size >= min(rulesizes))
rulespace <- data.frame(rulesize = rulesizes,
isolatesize = isolatesizes$n)
## Create empty dataframe
mcr_rules_df <- data.frame(
lhs = character(0),
rhs = character(0),
size = numeric(0),
support = numeric(0),
confidence = numeric(0),
lift = numeric(0),
count = numeric(0)
)
for (i in 1:nrow(rulespace)){
## Get rule size and support metric for this iteration
size <- rulespace$rulesize[i]
numerator <- rulespace$isolatesize[i]
cat("Testing rules of size:", size, "\n")
## Generate MCR Rules
mcr_rules<- apriori(mcr.transactions,
parameter = list(minlen = size,
maxlen = size,
#support = 0.002,
#support = 5*(numerator/length(amr.list.raw)),
support = 0.5*(numerator/length(amr.list.raw)),
confidence =  0.75,
maxtime = 60),
appearance = list(default = "none",
lhs = genotypes[which(genotypes != "mcr")],
rhs = "mcr"),
control = list(memopt = FALSE)
)
if (length(mcr_rules) > 0){
## Convert to dataframe
mcr_rules_df_iter <- data.frame(
lhs = labels(lhs(mcr_rules)),
rhs = labels(rhs(mcr_rules)),
size = size,
mcr_rules@quality
)
## Append this iterations's results to main dataframe
mcr_rules_df <- rbind(mcr_rules_df,
mcr_rules_df_iter)
}
}
## Remove brackets and convert all sets to lists
mcr_rules_df$lhs <- mcr_rules_df$lhs %>%
str_replace_all(c("\\{|\\}"),"") #%>%
mcr_rules_df$rhs <- mcr_rules_df$rhs %>%
str_replace_all(c("\\{|\\}"),"")
mcr_rules_df$rule <- paste0(mcr_rules_df$lhs, ",", mcr_rules_df$rhs) %>%
strsplit(split=",")
## Create strings of each genotype
mcrgenotypes <- sapply(mcr.subset, function(x){unlist(x) %>% paste0(collapse = ",")}) %>%
as.data.frame()
colnames(mcrgenotypes) <- "genotype"
## Create Empty Dataframe of All PDTs with MCR
matches <- data.frame(pdt = names(mcr.subset),
genotype = mcrgenotypes$genotype)
## Create a function to compare the rule vs. the genotype sets
comparefxn <- function(a, b){
if(setequal(a, unlist(b))){
response <- "Match"
} else if(all(a %in% b)){
response <- "Subset"
} else if(all(b %in% a)){
response <- "Superset"
} else{
response <- NA
}
return(response)
}
## Loop through each rule and see if any exist in the MCR Subset
for (i in 1:nrow(mcr_rules_df)){
rulename <- paste0(mcr_rules_df$lhs[i], "=>", mcr_rules_df$rhs[i])
rulelhs <- mcr_rules_df$lhs[i] %>%
strsplit(split=",") %>%
unlist()
cat(i, ". ", rulename, "\n", sep = "")
# itermatches <- sapply(mcr.subset, function(x){setequal(rulelhs, unlist(x))}) %>%
#   as.data.frame()
itermatches <- sapply(mcr.subset, function(x){comparefxn(rulelhs, x)}) %>%
as.data.frame()
colnames(itermatches) <- rulename
rownames(itermatches) <- names(mcr.subset)
matches <- cbind(matches, itermatches) ## Append to dataframe
}
View(matches)
## Reshape to Get only Subsets/Supersets/Matches
library(reshape2)
outputpdts <- melt(matches, id = c("pdt", "genotype"))
View(outputpdts)
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset")
View(outputpdts)
View(outputpdts)
length(unique(outputpdts$pdt))
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset") %>%
select(!value)
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset") %>%
select(!"value")
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset") %>%
select("value")
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset") %>%
select("!value")
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset") %>%
select(-one_of("value"))
View(outputpdts)
colnames(outputpdts) <- c("pdt", "genotype", "mcr_group")
write.csv(outputpdts, "MCR_Groups_ARM_PDTs.csv")
## Load in Packages
library(jsonlite)
library(tidyr)
library(dplyr)
## Generate New Extract from the NCBI Database
#json.stream <- fromJSON("https://www.ncbi.nlm.nih.gov/pathogens/ngram?start=0&limit=100000&q=%5Bdisplay()%2Chist(geo_loc_name%2Cisolation_source%2Ccollected_by%2Chost%2Cproperty%2Ctarget_creation_date)%5D.from(pathogen).usingschema(%2Fschema%2Fpathogen).matching(status%3D%3D%5B%22current%22%5D+and+q%3D%3D%22taxgroup_name%253A%2522E.coli%2520and%2520Shigella%2522%22).sort(target_creation_date%2Cdesc)&_search=false&rows=20&page=1&sidx=target_creation_date&sord=desc)")
#saveRDS(json.stream, file = "json.stream.RDS")
## Read in Data
json.stream <- readRDS("e.coli.RDS")
## Get IDs
id <- json.stream[["ngout"]][["data"]][["content"]][["id"]] %>% as.data.frame()
colnames(id) <- "id"
## Separate IDs into PDG and PDT numbers
ids <- id %>% separate(id, c("pdg", "pdt"), sep = "_")
## Get BioProject numbers
bioprojects <- json.stream[["ngout"]][["data"]][["content"]][["bioproject_acc"]] %>% as.data.frame()
colnames(bioprojects) <- "bioproject"
bioprojects <- data.frame(ids, bioprojects)
bioprojects$bioproject_url <- paste0("https://www.ncbi.nlm.nih.gov/bioproject/",bioprojects$bioproject)
## Join to MCR Groups (from Odds Ratio Analysis)
# mcr_groups <- read.csv("MCR_Groups_PDTs.csv")
mcr_groups <- read.csv("MCR_Groups_ARM_PDTs.csv")
bioprojects <- inner_join(mcr_groups, bioprojects)
## Find all citations
library(rvest)
library(stringr)
library(reshape)
bioprojects_unique <- unique(bioprojects$bioproject)
publications <- data.frame(bioproject = character(0),
publications = character(0))
for (i in 1:length(bioprojects_unique)){
bioproject <- bioprojects_unique[i]
# content <- read_html(paste0("https://www.ncbi.nlm.nih.gov/bioproject/",
#                             bioprojects_unique[i])) %>%
#   html_nodes('#CombinedTable') %>%
#   html_table() %>%
#   .[[1]] %>%
#   filter(X1 == "Publications") %>%
#   select(X2)
content <- read_html(paste0("https://www.ncbi.nlm.nih.gov/bioproject/",
bioprojects_unique[i])) %>%
html_nodes("a.RegularLink") %>%
html_attr("href") %>%
as.data.frame() %>%
filter(str_detect(., "/pubmed/")) %>%
.[[1]] %>%
as.data.frame()
colnames(content) <- "publications"
if (length(content$publications) > 0){
iteroutput <- data.frame(bioproject = bioproject,
publications = content)
publications <- rbind(publications, iteroutput)
}
cat(paste0(i, ".BioProject: ", as.character(bioprojects_unique[i]), "\n"))
}
library(jsonlite)
library(tidyr)
library(dplyr)
## Generate New Extract from the NCBI Database
#json.stream <- fromJSON("https://www.ncbi.nlm.nih.gov/pathogens/ngram?start=0&limit=100000&q=%5Bdisplay()%2Chist(geo_loc_name%2Cisolation_source%2Ccollected_by%2Chost%2Cproperty%2Ctarget_creation_date)%5D.from(pathogen).usingschema(%2Fschema%2Fpathogen).matching(status%3D%3D%5B%22current%22%5D+and+q%3D%3D%22taxgroup_name%253A%2522E.coli%2520and%2520Shigella%2522%22).sort(target_creation_date%2Cdesc)&_search=false&rows=20&page=1&sidx=target_creation_date&sord=desc)")
#saveRDS(json.stream, file = "json.stream.RDS")
## Read in Data
json.stream <- readRDS("e.coli.RDS")
## Load in Packages
library(jsonlite)
library(tidyr)
library(dplyr)
## Read in Data
json.stream <- readRDS("e.coli.RDS")
## Get IDs
id <- json.stream[["ngout"]][["data"]][["content"]][["id"]] %>% as.data.frame()
colnames(id) <- "id"
## Separate IDs into PDG and PDT numbers
ids <- id %>% separate(id, c("pdg", "pdt"), sep = "_")
## Get BioProject numbers
bioprojects <- json.stream[["ngout"]][["data"]][["content"]][["bioproject_acc"]] %>% as.data.frame()
colnames(bioprojects) <- "bioproject"
bioprojects <- data.frame(ids, bioprojects)
bioprojects$bioproject_url <- paste0("https://www.ncbi.nlm.nih.gov/bioproject/",bioprojects$bioproject)
## Join to MCR Groups (from Odds Ratio Analysis)
# mcr_groups <- read.csv("MCR_Groups_PDTs.csv")
mcr_groups <- read.csv("MCR_Groups_ARM_PDTs.csv")
bioprojects <- inner_join(mcr_groups, bioprojects)
View(bioprojects)
View(mcr_groups)
## Read in Data
json.stream <- readRDS("e.coli.RDS")
## Get IDs
id <- json.stream[["ngout"]][["data"]][["content"]][["id"]] %>% as.data.frame()
colnames(id) <- "id"
## Separate IDs into PDG and PDT numbers
ids <- id %>% separate(id, c("pdg", "pdt"), sep = "_")
## Get BioProject numbers
bioprojects <- json.stream[["ngout"]][["data"]][["content"]][["bioproject_acc"]] %>% as.data.frame()
View(bioprojects)
colnames(bioprojects) <- "bioproject"
bioprojects <- data.frame(ids, bioprojects)
bioprojects$bioproject_url <- paste0("https://www.ncbi.nlm.nih.gov/bioproject/",bioprojects$bioproject)
View(bioprojects)
## Load in Packages
library(jsonlite)
library(stringr)
library(dplyr)
library(tidyr)
library(arules)
## Generate New Extract from the NcBI Database
#json.stream <- fromJSON("https://www.ncbi.nlm.nih.gov/pathogens/ngram?start=0&limit=100000&q=%5Bdisplay()%2Chist(geo_loc_name%2Cisolation_source%2Ccollected_by%2Chost%2Cproperty%2Ctarget_creation_date)%5D.from(pathogen).usingschema(%2Fschema%2Fpathogen).matching(status%3D%3D%5B%22current%22%5D+and+q%3D%3D%22taxgroup_name%253A%2522E.coli%2520and%2520Shigella%2522%22).sort(target_creation_date%2Cdesc)&_search=false&rows=20&page=1&sidx=target_creation_date&sord=desc)")
#saveRDS(json.stream, file = "json.stream.RDS")
## Read in Data
json.stream <- readRDS("e.coli.RDS")
amr.list.raw <- json.stream[["ngout"]][["data"]][["content"]][["AMR_genotypes"]]
names(amr.list.raw) <- json.stream[["ngout"]][["data"]][["content"]][["id"]]
amr.list.raw[amr.list.raw == "NULL"] <- NULL
amr.all <- sort(unique(unlist(amr.list.raw)))
## Find all mcr variants
# mcr.variants <- amr.all[str_detect(amr.all, "mcr-1|mcr-2")] %>%
mcr.variants <- amr.all[str_detect(amr.all, "mcr-")] %>%
sort(decreasing = TRUE) %>%
paste0(collapse = "|")
## Convert all mcr genotype variants to "mcr"
mcr.subset <- amr.list.raw %>%
lapply(., str_replace_all, pattern = mcr.variants, replacement = "mcr") %>%
lapply(., unique) # Removes duplicate "mcr" genotypes from previous step
genotypes <- sort(unique(unlist(mcr.subset)))
## Convert to transactions for the a priori algorithm
mcr.transactions <- as(mcr.subset, 'transactions')
mcr_rules<- apriori(mcr.transactions,
parameter = list(minlen = 2,
maxlen = 14,
support = (200/length(genotypes))-1,
confidence =  0.5),
appearance = list(default = "none",
lhs = genotypes[which(genotypes != "mcr")],
rhs = "mcr"),
control = list(memopt = FALSE)
)
## Define rule sizes and isolate counts to explore
rulesizes <- seq(2, 14, by = 1)
isolatesizes <- lapply(amr.list.raw, length) %>%
matrix() %>%
data.frame()
colnames(isolatesizes) <- c("size")
isolatesizes$size <- as.factor(as.character(isolatesizes$size))
isolatesizes <- isolatesizes %>%
group_by(size) %>%
tally()
isolatesizes$size <- as.numeric(isolatesizes$size)
isolatesizes <- isolatesizes %>%
arrange() %>%
filter(size <= max(rulesizes) & size >= min(rulesizes))
rulespace <- data.frame(rulesize = rulesizes,
isolatesize = isolatesizes$n)
## Create empty dataframe
mcr_rules_df <- data.frame(
lhs = character(0),
rhs = character(0),
size = numeric(0),
support = numeric(0),
confidence = numeric(0),
lift = numeric(0),
count = numeric(0)
)
for (i in 1:nrow(rulespace)){
## Get rule size and support metric for this iteration
size <- rulespace$rulesize[i]
numerator <- rulespace$isolatesize[i]
cat("Testing rules of size:", size, "\n")
## Generate MCR Rules
mcr_rules<- apriori(mcr.transactions,
parameter = list(minlen = size,
maxlen = size,
#support = 0.002,
#support = 5*(numerator/length(amr.list.raw)),
support = 0.5*(numerator/length(amr.list.raw)),
confidence =  0.75,
maxtime = 60),
appearance = list(default = "none",
lhs = genotypes[which(genotypes != "mcr")],
rhs = "mcr"),
control = list(memopt = FALSE)
)
if (length(mcr_rules) > 0){
## Convert to dataframe
mcr_rules_df_iter <- data.frame(
lhs = labels(lhs(mcr_rules)),
rhs = labels(rhs(mcr_rules)),
size = size,
mcr_rules@quality
)
## Append this iterations's results to main dataframe
mcr_rules_df <- rbind(mcr_rules_df,
mcr_rules_df_iter)
}
}
## Remove brackets and convert all sets to lists
mcr_rules_df$lhs <- mcr_rules_df$lhs %>%
str_replace_all(c("\\{|\\}"),"") #%>%
mcr_rules_df$rhs <- mcr_rules_df$rhs %>%
str_replace_all(c("\\{|\\}"),"")
mcr_rules_df$rule <- paste0(mcr_rules_df$lhs, ",", mcr_rules_df$rhs) %>%
strsplit(split=",")
## Create strings of each genotype
mcrgenotypes <- sapply(mcr.subset, function(x){unlist(x) %>% paste0(collapse = ",")}) %>%
as.data.frame()
colnames(mcrgenotypes) <- "genotype"
## Create Empty Dataframe of All PDTs with MCR
matches <- data.frame(pdt = names(mcr.subset),
genotype = mcrgenotypes$genotype)
## Create a function to compare the rule vs. the genotype sets
comparefxn <- function(a, b){
if(setequal(a, unlist(b))){
response <- "Match"
} else if(all(a %in% b)){
response <- "Subset"
} else if(all(b %in% a)){
response <- "Superset"
} else{
response <- NA
}
return(response)
}
## Loop through each rule and see if any exist in the MCR Subset
for (i in 1:nrow(mcr_rules_df)){
rulename <- paste0(mcr_rules_df$lhs[i], "=>", mcr_rules_df$rhs[i])
rulelhs <- mcr_rules_df$lhs[i] %>%
strsplit(split=",") %>%
unlist()
cat(i, ". ", rulename, "\n", sep = "")
# itermatches <- sapply(mcr.subset, function(x){setequal(rulelhs, unlist(x))}) %>%
#   as.data.frame()
itermatches <- sapply(mcr.subset, function(x){comparefxn(rulelhs, x)}) %>%
as.data.frame()
colnames(itermatches) <- rulename
rownames(itermatches) <- names(mcr.subset)
matches <- cbind(matches, itermatches) ## Append to dataframe
}
colnames(outputpdts) <- c("id", "genotype", "mcr_group")
## Reshape to Get only Subsets/Supersets/Matches
library(reshape2)
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset") %>%
select(-one_of("value"))
colnames(outputpdts) <- c("id", "genotype", "mcr_group")
View(outputpdts)
## Separate IDs into PDG and PDT numbers
outputpdts <- outputpdts %>% separate(id, c("pdg", "pdt"), sep = "_")
View(outputpdts)
write.csv(outputpdts, "MCR_Groups_ARM_PDTs.csv")
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset") %>%
select(-one_of("value"))
colnames(outputpdts) <- c("id", "genotype", "mcr_group")
## Separate IDs into PDG and PDT numbers
outputpdts <- outputpdts %>%
separate(id, c("pdg", "pdt"), sep = "_") %>%
select(-one_of("pdg"))
View(outputpdts)
write.csv(outputpdts, "MCR_Groups_ARM_PDTs.csv")
bioprojects$bioproject_url <- paste0("https://www.ncbi.nlm.nih.gov/bioproject/",bioprojects$bioproject)
## Join to MCR Groups (from Odds Ratio Analysis)
# mcr_groups <- read.csv("MCR_Groups_PDTs.csv")
mcr_groups <- read.csv("MCR_Groups_ARM_PDTs.csv")
View(mcr_groups)
readr::write_csv(outputpdts, "MCR_Groups_ARM_PDTs.csv")
## Join to MCR Groups (from Odds Ratio Analysis)
# mcr_groups <- read.csv("MCR_Groups_PDTs.csv")
mcr_groups <- read.csv("MCR_Groups_ARM_PDTs.csv")
bioprojects <- inner_join(mcr_groups, bioprojects)
View(bioprojects)
######################
## Find all citations
library(rvest)
library(stringr)
library(reshape)
bioprojects_unique <- unique(bioprojects$bioproject)
publications <- data.frame(bioproject = character(0),
publications = character(0))
for (i in 1:length(bioprojects_unique)){
bioproject <- bioprojects_unique[i]
# content <- read_html(paste0("https://www.ncbi.nlm.nih.gov/bioproject/",
#                             bioprojects_unique[i])) %>%
#   html_nodes('#CombinedTable') %>%
#   html_table() %>%
#   .[[1]] %>%
#   filter(X1 == "Publications") %>%
#   select(X2)
content <- read_html(paste0("https://www.ncbi.nlm.nih.gov/bioproject/",
bioprojects_unique[i])) %>%
html_nodes("a.RegularLink") %>%
html_attr("href") %>%
as.data.frame() %>%
filter(str_detect(., "/pubmed/")) %>%
.[[1]] %>%
as.data.frame()
colnames(content) <- "publications"
if (length(content$publications) > 0){
iteroutput <- data.frame(bioproject = bioproject,
publications = content)
publications <- rbind(publications, iteroutput)
}
cat(paste0(i, ".BioProject: ", as.character(bioprojects_unique[i]), "\n"))
}
#publications_orig <- publications
## Derive URLS for Publications
publications$publication_url <- paste0("https://www.ncbi.nlm.nih.gov", publications$publications)
## Join Publications to PDT numbers via BioProject
publication_output <- inner_join(publications, bioprojects)
publications_by_mcr_group <- publication_output %>%
select(-c("pdt", "pdg", "publications", "bioproject")) %>%
unique() %>%
cast(publication_url~mcr_group)
View(publications_by_mcr_group)
View(publication_output)
## Separate IDs into PDG and PDT numbers
outputpdts <- outputpdts %>%
separate(id, c("pdg", "pdt"), sep = "_") %>%
select(-c("pdg","genotype"))
outputpdts <- melt(matches, id = c("pdt", "genotype")) %>%
filter(value == "Subset") %>%
select(-one_of("value"))
colnames(outputpdts) <- c("id", "genotype", "mcr_group")
## Separate IDs into PDG and PDT numbers
outputpdts <- outputpdts %>%
separate(id, c("pdg", "pdt"), sep = "_") %>%
select(-c("pdg","genotype"))
View(outputpdts)
readr::write_csv(outputpdts, "MCR_Groups_ARM_PDTs.csv")
## Get BioProject numbers
bioprojects <- json.stream[["ngout"]][["data"]][["content"]][["bioproject_acc"]] %>% as.data.frame()
colnames(bioprojects) <- "bioproject"
bioprojects <- data.frame(ids, bioprojects)
bioprojects$bioproject_url <- paste0("https://www.ncbi.nlm.nih.gov/bioproject/",bioprojects$bioproject)
## Join to MCR Groups (from Odds Ratio Analysis)
# mcr_groups <- read.csv("MCR_Groups_PDTs.csv")
mcr_groups <- read.csv("MCR_Groups_ARM_PDTs.csv")
bioprojects <- inner_join(mcr_groups, bioprojects)
######################
## Find all citations
library(rvest)
library(stringr)
library(reshape)
bioprojects_unique <- unique(bioprojects$bioproject)
publications <- data.frame(bioproject = character(0),
publications = character(0))
for (i in 1:length(bioprojects_unique)){
bioproject <- bioprojects_unique[i]
# content <- read_html(paste0("https://www.ncbi.nlm.nih.gov/bioproject/",
#                             bioprojects_unique[i])) %>%
#   html_nodes('#CombinedTable') %>%
#   html_table() %>%
#   .[[1]] %>%
#   filter(X1 == "Publications") %>%
#   select(X2)
content <- read_html(paste0("https://www.ncbi.nlm.nih.gov/bioproject/",
bioprojects_unique[i])) %>%
html_nodes("a.RegularLink") %>%
html_attr("href") %>%
as.data.frame() %>%
filter(str_detect(., "/pubmed/")) %>%
.[[1]] %>%
as.data.frame()
colnames(content) <- "publications"
if (length(content$publications) > 0){
iteroutput <- data.frame(bioproject = bioproject,
publications = content)
publications <- rbind(publications, iteroutput)
}
cat(paste0(i, ". BioProject: ", as.character(bioprojects_unique[i]), "\n"))
}
#publications_orig <- publications
## Derive URLS for Publications
publications$publication_url <- paste0("https://www.ncbi.nlm.nih.gov", publications$publications)
## Join Publications to PDT numbers via BioProject
publication_output <- inner_join(publications, bioprojects)
publications_by_mcr_group <- publication_output %>%
select(-c("pdt", "pdg", "publications", "bioproject")) %>%
unique() %>%
cast(publication_url~mcr_group)
View(publications_by_mcr_group)
# write.csv(publications_by_mcr_group, "publications_by_mcr_group.csv")
write.csv(publications_by_mcr_group, "publications_by_ARM_mcr_group.csv")
